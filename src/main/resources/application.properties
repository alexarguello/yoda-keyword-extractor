vaadin.launch-browser=true
spring.application.name=yoda-keyword-extractor
# Enable Ollama as the active chat model (default)
spring.ai.model.chat=ollama
# Point to your local Ollama HTTP API
spring.ai.ollama.base-url=localhost:11434
# Choose which model to use (e.g. llama3.2, mistral, etc.)
spring.ai.ollama.chat.options.model=llama3.2
